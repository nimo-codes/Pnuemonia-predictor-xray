{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./chest_xray/train/\"\n",
    "test_dir = \"./chest_xray/test/\"\n",
    "val_dir = \"./chest_xray/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=0.4,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  zoom_range=0.2, \n",
    "                            )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=0.4,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  zoom_range=0.2, \n",
    "                            )\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=0.4,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  zoom_range=0.2, \n",
    "                            )\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 00:02:57.514504: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-03 00:02:57.514792: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (300,300,3)),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n",
    "                                keras.layers.Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n",
    "                                keras.layers.Dropout(0.1),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n",
    "                                keras.layers.Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n",
    "                                keras.layers.Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n",
    "                                keras.layers.Dropout(0.2),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n",
    "                                keras.layers.Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n",
    "                                keras.layers.Dropout(0.2),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n",
    "                                keras.layers.Flatten(),\n",
    "                                keras.layers.Dense(units = 128 , activation = 'relu'),\n",
    "                                keras.layers.Dropout(0.2),\n",
    "                                keras.layers.Dense(units = 1 , activation = 'sigmoid')])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = RMSprop(learning_rate=0.001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:ModelCheckpoint mode <built-in function max> is unknown, fallback to auto mode.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_path = \"/Users/jarvis/pymycod/tensorflow_AI/trained_models/lr_model_chest_xray.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path,monitor=\"val_accuracy\",verbose=1,save_best_only=True,mode=max)\n",
    "callbacks_list=[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 00:02:59.482128: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-03 00:03:00.134654: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-03 00:09:34.150548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62500, saving model to /Users/jarvis/pymycod/tensorflow_AI/trained_models/lr_model_chest_xray.h5\n",
      "41/41 - 404s - loss: 1.7113 - accuracy: 0.8457 - val_loss: 11.0067 - val_accuracy: 0.6250 - 404s/epoch - 10s/step\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.62500\n",
      "41/41 - 433s - loss: 0.2928 - accuracy: 0.8871 - val_loss: 30.3456 - val_accuracy: 0.6250 - 433s/epoch - 11s/step\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.62500\n",
      "41/41 - 379s - loss: 0.2824 - accuracy: 0.8963 - val_loss: 39.0660 - val_accuracy: 0.6250 - 379s/epoch - 9s/step\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jarvis/pymycod/tensorflow_AI/chest_xray.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jarvis/pymycod/tensorflow_AI/chest_xray.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mtest_generator,callbacks\u001b[39m=\u001b[39;49mcallbacks_list)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/keras/engine/training.py:1401\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1400\u001b[0m   data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1402\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m         epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m         step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m         _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m       callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/keras/engine/data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1249\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1250\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m   1253\u001b[0m     original_spe)\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,epochs=10,verbose=2,batch_size=128,validation_data=test_generator,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model1 = load_model('./trained_models/model_catsvsdogs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "[[2.3588222e-13]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.3588222e-13]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_name = 36\n",
    "import numpy as np\n",
    "import keras.utils as image\n",
    "\n",
    "img_width, img_height = 300, 300\n",
    "img = image.load_img(f'/Users/jarvis/pymycod/tensorflow_AI/chest_xray/val/PNEUMONIA/person1954_bacteria_4886.jpeg', target_size = (img_width, img_height))\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "ans = model1.predict(img)\n",
    "print(ans)\n",
    "ans\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0139c45f3101d02256c49e404c69cbeadb20492fa8d7c464de4f3d908da00b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
